{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.openai_assistant import OpenAIAssistantRunnable\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "from langchain.tools import E2BDataAnalysisTool\n",
    "import os\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.agents import tool, initialize_agent, AgentType, Tool\n",
    "from langchain.chat_models import AzureChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "E2B_API_KEY = os.getenv(\"E2B_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "# tavily_tool = TavilySearchResults(\n",
    "#     description=\"A search engine. Useful for when you don't know something and want to find it out.\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread e2b-sandbox-refresh:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\e2b\\sandbox\\sandbox_connection.py\", line 433, in _refresh\n",
      "    api.sandboxes_sandbox_id_refreshes_post(\n",
      "  File \"c:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\pydantic\\validate_call_decorator.py\", line 58, in wrapper_function\n",
      "    return validate_call_wrapper(*args, **kwargs)\n",
      "  File \"c:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\pydantic\\_internal\\_validate_call.py\", line 81, in __call__\n",
      "    res = self.__pydantic_validator__.validate_python(pydantic_core.ArgsKwargs(args, kwargs))\n",
      "  File \"c:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\e2b\\api\\v2\\client\\api\\sandboxes_api.py\", line 838, in sandboxes_sandbox_id_refreshes_post\n",
      "    return self.api_client.response_deserialize(\n",
      "  File \"c:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\e2b\\api\\v2\\client\\api_client.py\", line 299, in response_deserialize\n",
      "    raise NotFoundException(http_resp=response_data)\n",
      "e2b.api.v2.client.exceptions.NotFoundException: (404)\n",
      "Reason: Not Found\n",
      "HTTP response headers: HTTPHeaderDict({'content-type': 'application/json; charset=utf-8', 'date': 'Thu, 21 Mar 2024 17:22:20 GMT', 'Content-Length': '97', 'via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\n",
      "HTTP response body: {\"code\":404,\"message\":\"Error refreshing sandbox - sandbox 'iywoe0y3whhz4wz5eh9sq' was not found\"}\n",
      "\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python39\\lib\\threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 761, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"C:\\Python39\\lib\\threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\e2b\\sandbox\\sandbox_connection.py\", line 440, in _refresh\n",
      "    raise SandboxException(\n",
      "e2b.sandbox.exception.SandboxException: Sandbox iywoe0y3whhz4wz5eh9sq-40c5eb20 failed because it cannot be found\n"
     ]
    }
   ],
   "source": [
    "e2b_data_analysis_tool = E2BDataAnalysisTool(api_key=E2B_API_KEY)\n",
    "#e2b_data_analysis_tool.install_python_packages(\"geopy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def install_python_package_to_e2b(package_name: str):\n",
    "    \"\"\"\n",
    "    Installs a python package to the E2B environment. This is useful for when you need to install a package that is not already installed in the E2B environment.\n",
    "    \"\"\"\n",
    "    e2b_data_analysis_tool.install_python_packages(package_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [e2b_data_analysis_tool, install_python_package_to_e2b]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can a normal gpt (not assitant do the same?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"\"\"\n",
    "'Aircraft ids: [\\'KL204\\', \\'KL420\\']\\nInfo on KL204 B744 index = 0\\nPos: N52\\'00\\'0.0\"  E004\\'00\\'0.0\"\\nHdg: 270   Trk: 270\\nAlt: 25000 ft  V/S: 0 fpm\\nCAS/TAS/GS: 350/498/498 kts   M: 0.827\\n\\nInfo on KL420 B744 index = 1\\nPos: N52\\'00\\'0.0\"  E003\\'12\\'0.0\"\\nHdg: 090   Trk: 090\\nAlt: 25000 ft  V/S: 0 fpm\\nCAS/TAS/GS: 350/498/498 kts   M: 0.827\\n\\n'\n",
    "\"\"\"\n",
    "\n",
    "question = f\"Based on this info what wil be the position of the closest approach point between these aircraft and after how much time will it happen: \\n\\n {txt}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on this info what wil be the position of the closest approach point between these aircraft and after how much time will it happen: \\n\\n \\n\\'Aircraft ids: [\\'KL204\\', \\'KL420\\']\\nInfo on KL204 B744 index = 0\\nPos: N52\\'00\\'0.0\"  E004\\'00\\'0.0\"\\nHdg: 270   Trk: 270\\nAlt: 25000 ft  V/S: 0 fpm\\nCAS/TAS/GS: 350/498/498 kts   M: 0.827\\n\\nInfo on KL420 B744 index = 1\\nPos: N52\\'00\\'0.0\"  E003\\'12\\'0.0\"\\nHdg: 090   Trk: 090\\nAlt: 25000 ft  V/S: 0 fpm\\nCAS/TAS/GS: 350/498/498 kts   M: 0.827\\n\\n\\'\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #llm = ChatOpenAI(model='gpt-4-0125-preview', temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "llm = ChatAnthropic(model='claude-3-opus-20240229', anthropic_api_key=os.getenv(\"ANTHROPIC_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.azure_openai.AzureChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import AzureChatOpenAI`.\n",
      "  warn_deprecated(\n",
      "c:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\langchain_community\\chat_models\\azure_openai.py:174: UserWarning: As of openai>=1.0.0, if `deployment_name` (or alias `azure_deployment`) is specified then `openai_api_base` (or alias `base_url`) should not be. Instead use `deployment_name` (or alias `azure_deployment`) and `azure_endpoint`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\langchain_community\\chat_models\\azure_openai.py:182: UserWarning: As of openai>=1.0.0, if `openai_api_base` (or alias `base_url`) is specified it is expected to be of the form https://example-resource.azure.openai.com/openai/deployments/example-deployment. Updating https://air-traffic-management-llm.openai.azure.com/openai to https://air-traffic-management-llm.openai.azure.com/openai.\n",
      "  warnings.warn(\n",
      "c:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n",
      "c:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo find the position of the closest approach point between the two aircraft and the time it will happen, I need to calculate their positions over time and determine when their paths will be the closest. I will first convert their positions from degrees, minutes, and seconds to decimal degrees for easier calculation. Then, I will simulate the movement of both aircraft based on their headings, speeds, and positions over time to find the point of closest approach.\n",
      "\n",
      "The aircraft are both at the same altitude, flying at the same speed in opposite directions toward each other on the same latitude, which simplifies the problem significantly. It's a head-on situation where the relative speed is the sum of their speeds, and the time until the closest approach is simply the initial distance between them divided by that relative speed.\n",
      "\n",
      "First, I need to convert the longitude of the second aircraft from degrees, minutes, and seconds to decimal degrees to determine the initial distance between them. Then, I'll use the ground speed of the aircraft to calculate the time until the closest approach and the position of that approach.\n",
      "\n",
      "Action: e2b_data_analysis\n",
      "Action Input:\n",
      "```python\n",
      "from geopy.distance import geodesic\n",
      "\n",
      "# Positions of aircraft KL204 and KL420 in decimal degrees\n",
      "pos_KL204 = (52.0, 4.0)\n",
      "pos_KL420 = (52.0, 3.0 + 12/60)  # converting 12 minutes to degrees\n",
      "\n",
      "# Calculate the initial distance between the two aircraft\n",
      "initial_distance_km = geodesic(pos_KL204, pos_KL420).kilometers\n",
      "\n",
      "# Speed of both aircraft in knots, converted to km/h for calculation\n",
      "speed_KL204_kmh = 498 * 1.852  # 1 knot = 1.852 km/h\n",
      "speed_KL420_kmh = 498 * 1.852\n",
      "\n",
      "# Calculate the relative speed (since they're heading towards each other)\n",
      "relative_speed_kmh = speed_KL204_kmh + speed_KL420_kmh\n",
      "\n",
      "# Calculate the time until the closest approach in hours\n",
      "time_until_closest_approach_hrs = initial_distance_km / relative_speed_kmh\n",
      "\n",
      "# Since both aircraft are at the same latitude and altitude, the closest point will also be at the same latitude and altitude\n",
      "# The longitude at the closest approach point will be the midpoint of the initial longitudes of the two aircraft\n",
      "longitude_closest_approach = (pos_KL204[1] + pos_KL420[1]) / 2\n",
      "\n",
      "# Output the results\n",
      "print(f\"Initial distance between KL204 and KL420: {initial_distance_km:.2f} km\")\n",
      "print(f\"Time until closest approach: {time_until_closest_approach_hrs * 60:.2f} minutes\")\n",
      "print(f\"Position of the closest approach point: (N52'00'0.0\\\", E{longitude_closest_approach:.2f}')\")\n",
      "```\u001b[0m"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<unknown>, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[0;32mc:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3550\u001b[0m in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[0;32mIn[18], line 23\u001b[0m\n    react.run(question)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mc:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:145\u001b[0m in \u001b[0;35mwarning_emitting_wrapper\u001b[0m\n    return wrapped(*args, **kwargs)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mc:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\langchain\\chains\\base.py:545\u001b[0m in \u001b[0;35mrun\u001b[0m\n    return self(args[0], callbacks=callbacks, tags=tags, metadata=metadata)[\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mc:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:145\u001b[0m in \u001b[0;35mwarning_emitting_wrapper\u001b[0m\n    return wrapped(*args, **kwargs)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mc:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\langchain\\chains\\base.py:378\u001b[0m in \u001b[0;35m__call__\u001b[0m\n    return self.invoke(\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mc:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\langchain\\chains\\base.py:163\u001b[0m in \u001b[0;35minvoke\u001b[0m\n    raise e\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mc:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\langchain\\chains\\base.py:153\u001b[0m in \u001b[0;35minvoke\u001b[0m\n    self._call(inputs, run_manager=run_manager)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mc:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\langchain\\agents\\agent.py:1432\u001b[0m in \u001b[0;35m_call\u001b[0m\n    next_step_output = self._take_next_step(\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mc:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\langchain\\agents\\agent.py:1138\u001b[0m in \u001b[0;35m_take_next_step\u001b[0m\n    [\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mc:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\langchain\\agents\\agent.py:1138\u001b[0m in \u001b[0;35m<listcomp>\u001b[0m\n    [\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mc:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\langchain\\agents\\agent.py:1223\u001b[0m in \u001b[0;35m_iter_next_step\u001b[0m\n    yield self._perform_agent_action(\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mc:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\langchain\\agents\\agent.py:1245\u001b[0m in \u001b[0;35m_perform_agent_action\u001b[0m\n    observation = tool.run(\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mc:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\langchain_core\\tools.py:417\u001b[0m in \u001b[0;35mrun\u001b[0m\n    raise e\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mc:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\langchain_core\\tools.py:376\u001b[0m in \u001b[0;35mrun\u001b[0m\n    self._run(*tool_args, run_manager=run_manager, **tool_kwargs)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mc:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\langchain_core\\tools.py:574\u001b[0m in \u001b[0;35m_run\u001b[0m\n    self.func(\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mc:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\langchain_community\\tools\\e2b_data_analysis\\tool.py:162\u001b[0m in \u001b[0;35m_run\u001b[0m\n    python_code = add_last_line_print(python_code)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mc:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\langchain_community\\tools\\e2b_data_analysis\\tool.py:56\u001b[0m in \u001b[0;35madd_last_line_print\u001b[0m\n    tree = ast.parse(code)\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32mC:\\Python39\\lib\\ast.py:50\u001b[1;36m in \u001b[1;35mparse\u001b[1;36m\n\u001b[1;33m    return compile(source, filename, mode, flags,\u001b[1;36m\n",
      "\u001b[1;36m  File \u001b[1;32m<unknown>:1\u001b[1;36m\u001b[0m\n\u001b[1;33m    ```python\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    openai_api_base='https://air-traffic-management-llm.openai.azure.com/openai',\n",
    "    openai_api_version=\"2023-03-15-preview\",\n",
    "    deployment_name=\"thesis\",\n",
    "    openai_api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    openai_api_type=\"azure\",\n",
    "    model_name=\"gpt-4\"\n",
    ")\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"install_python_package_to_e2b\",\n",
    "        func=lambda x: install_python_package_to_e2b(x),\n",
    "        description=\"use when you need to install a python package to the E2B environment\"\n",
    "    ),\n",
    "\n",
    "    e2b_data_analysis_tool.as_tool()\n",
    "]\n",
    "\n",
    "react = initialize_agent(\n",
    "    tools, llm, verbose=True)\n",
    "\n",
    "react.run(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ChatAnthropic' object has no attribute 'bind_tools'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 22\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# gpt-4-0125-preview\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Create a chat prompt template\u001b[39;00m\n\u001b[0;32m     11\u001b[0m prompt \u001b[38;5;241m=\u001b[39m ChatPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_messages(\n\u001b[0;32m     12\u001b[0m     [\n\u001b[0;32m     13\u001b[0m         (\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m     ]\n\u001b[0;32m     20\u001b[0m )\n\u001b[1;32m---> 22\u001b[0m llm_with_tools \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind_tools\u001b[49m(tools)\n\u001b[0;32m     24\u001b[0m agent \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     25\u001b[0m     {\n\u001b[0;32m     26\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;241m|\u001b[39m OpenAIToolsAgentOutputParser()\n\u001b[0;32m     34\u001b[0m )\n\u001b[0;32m     36\u001b[0m agent_executor \u001b[38;5;241m=\u001b[39m AgentExecutor(\n\u001b[0;32m     37\u001b[0m     agent\u001b[38;5;241m=\u001b[39magent, tools\u001b[38;5;241m=\u001b[39mtools, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, return_intermediate_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ChatAnthropic' object has no attribute 'bind_tools'"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents.format_scratchpad.openai_tools import (\n",
    "    format_to_openai_tool_messages,\n",
    ")\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser\n",
    "\n",
    "# gpt-4-0125-preview\n",
    "# Create a chat prompt template\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are very powerful air taffic control operator, that can also use tools to answer questions and perform tasks\",\n",
    "        ),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_tool_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | OpenAIToolsAgentOutputParser()\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent, tools=tools, verbose=True, return_intermediate_steps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43magent_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\langchain\\chains\\base.py:163\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    162\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    164\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[1;32mc:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\langchain\\chains\\base.py:153\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[0;32m    152\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 153\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    155\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    156\u001b[0m     )\n\u001b[0;32m    158\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    159\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[0;32m    160\u001b[0m     )\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\langchain\\agents\\agent.py:1432\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m   1430\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[0;32m   1431\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[1;32m-> 1432\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1434\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1435\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1438\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[0;32m   1440\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(\n\u001b[0;32m   1441\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[38;5;241m=\u001b[39mrun_manager\n\u001b[0;32m   1442\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\langchain\\agents\\agent.py:1138\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m   1129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[0;32m   1130\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1131\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1135\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1136\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[0;32m   1137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[1;32m-> 1138\u001b[0m         [\n\u001b[0;32m   1139\u001b[0m             a\n\u001b[0;32m   1140\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_next_step(\n\u001b[0;32m   1141\u001b[0m                 name_to_tool_map,\n\u001b[0;32m   1142\u001b[0m                 color_mapping,\n\u001b[0;32m   1143\u001b[0m                 inputs,\n\u001b[0;32m   1144\u001b[0m                 intermediate_steps,\n\u001b[0;32m   1145\u001b[0m                 run_manager,\n\u001b[0;32m   1146\u001b[0m             )\n\u001b[0;32m   1147\u001b[0m         ]\n\u001b[0;32m   1148\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\langchain\\agents\\agent.py:1138\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[0;32m   1130\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1131\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1135\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1136\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[0;32m   1137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[1;32m-> 1138\u001b[0m         [\n\u001b[0;32m   1139\u001b[0m             a\n\u001b[0;32m   1140\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_next_step(\n\u001b[0;32m   1141\u001b[0m                 name_to_tool_map,\n\u001b[0;32m   1142\u001b[0m                 color_mapping,\n\u001b[0;32m   1143\u001b[0m                 inputs,\n\u001b[0;32m   1144\u001b[0m                 intermediate_steps,\n\u001b[0;32m   1145\u001b[0m                 run_manager,\n\u001b[0;32m   1146\u001b[0m             )\n\u001b[0;32m   1147\u001b[0m         ]\n\u001b[0;32m   1148\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\langchain\\agents\\agent.py:1166\u001b[0m, in \u001b[0;36mAgentExecutor._iter_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m   1163\u001b[0m     intermediate_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_intermediate_steps(intermediate_steps)\n\u001b[0;32m   1165\u001b[0m     \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[1;32m-> 1166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent\u001b[38;5;241m.\u001b[39mplan(\n\u001b[0;32m   1167\u001b[0m         intermediate_steps,\n\u001b[0;32m   1168\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1169\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs,\n\u001b[0;32m   1170\u001b[0m     )\n\u001b[0;32m   1171\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1172\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\langchain\\agents\\agent.py:514\u001b[0m, in \u001b[0;36mRunnableMultiActionAgent.plan\u001b[1;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    506\u001b[0m final_output: Any \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_runnable:\n\u001b[0;32m    508\u001b[0m     \u001b[38;5;66;03m# Use streaming to make sure that the underlying LLM is invoked in a\u001b[39;00m\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;66;03m# streaming\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;66;03m# Because the response from the plan is not a generator, we need to\u001b[39;00m\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;66;03m# accumulate the output into final output and return that.\u001b[39;00m\n\u001b[1;32m--> 514\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunnable\u001b[38;5;241m.\u001b[39mstream(inputs, config\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks}):\n\u001b[0;32m    515\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m final_output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    516\u001b[0m             final_output \u001b[38;5;241m=\u001b[39m chunk\n",
      "File \u001b[1;32mc:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\langchain_core\\runnables\\base.py:2460\u001b[0m, in \u001b[0;36mRunnableSequence.stream\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   2454\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstream\u001b[39m(\n\u001b[0;32m   2455\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2456\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[0;32m   2457\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2458\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   2459\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[1;32m-> 2460\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28miter\u001b[39m([\u001b[38;5;28minput\u001b[39m]), config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\langchain_core\\runnables\\base.py:2447\u001b[0m, in \u001b[0;36mRunnableSequence.transform\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   2441\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\n\u001b[0;32m   2442\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2443\u001b[0m     \u001b[38;5;28minput\u001b[39m: Iterator[Input],\n\u001b[0;32m   2444\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2445\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   2446\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[1;32m-> 2447\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_stream_with_config(\n\u001b[0;32m   2448\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   2449\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform,\n\u001b[0;32m   2450\u001b[0m         patch_config(config, run_name\u001b[38;5;241m=\u001b[39m(config \u001b[38;5;129;01mor\u001b[39;00m {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m   2451\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2452\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\langchain_core\\runnables\\base.py:1527\u001b[0m, in \u001b[0;36mRunnable._transform_stream_with_config\u001b[1;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1526\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1527\u001b[0m         chunk: Output \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m   1528\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[0;32m   1529\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m final_output_supported:\n",
      "File \u001b[1;32mc:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\langchain_core\\runnables\\base.py:2411\u001b[0m, in \u001b[0;36mRunnableSequence._transform\u001b[1;34m(self, input, run_manager, config)\u001b[0m\n\u001b[0;32m   2402\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m steps:\n\u001b[0;32m   2403\u001b[0m     final_pipeline \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[0;32m   2404\u001b[0m         final_pipeline,\n\u001b[0;32m   2405\u001b[0m         patch_config(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2408\u001b[0m         ),\n\u001b[0;32m   2409\u001b[0m     )\n\u001b[1;32m-> 2411\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m final_pipeline:\n\u001b[0;32m   2412\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\langchain_core\\runnables\\base.py:1051\u001b[0m, in \u001b[0;36mRunnable.transform\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   1048\u001b[0m final: Input\n\u001b[0;32m   1049\u001b[0m got_first_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1051\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28minput\u001b[39m:\n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m got_first_val:\n\u001b[0;32m   1053\u001b[0m         final \u001b[38;5;241m=\u001b[39m _adapt_first_streaming_chunk(chunk)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\langchain_core\\runnables\\base.py:4194\u001b[0m, in \u001b[0;36mRunnableBindingBase.transform\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   4188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\n\u001b[0;32m   4189\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4190\u001b[0m     \u001b[38;5;28minput\u001b[39m: Iterator[Input],\n\u001b[0;32m   4191\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   4192\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   4193\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[1;32m-> 4194\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[0;32m   4195\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   4196\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[0;32m   4197\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[0;32m   4198\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\langchain_core\\runnables\\base.py:1068\u001b[0m, in \u001b[0;36mRunnable.transform\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   1061\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   1062\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed while trying to add together \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1063\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(final)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(chunk)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1064\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThese types should be addable for transform to work.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1065\u001b[0m             )\n\u001b[0;32m   1067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m got_first_val:\n\u001b[1;32m-> 1068\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(final, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:258\u001b[0m, in \u001b[0;36mBaseChatModel.stream\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    252\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(\n\u001b[0;32m    253\u001b[0m         e,\n\u001b[0;32m    254\u001b[0m         response\u001b[38;5;241m=\u001b[39mLLMResult(\n\u001b[0;32m    255\u001b[0m             generations\u001b[38;5;241m=\u001b[39m[[generation]] \u001b[38;5;28;01mif\u001b[39;00m generation \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[0;32m    256\u001b[0m         ),\n\u001b[0;32m    257\u001b[0m     )\n\u001b[1;32m--> 258\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    260\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_llm_end(LLMResult(generations\u001b[38;5;241m=\u001b[39m[[generation]]))\n",
      "File \u001b[1;32mc:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:241\u001b[0m, in \u001b[0;36mBaseChatModel.stream\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    239\u001b[0m generation: Optional[ChatGenerationChunk] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 241\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream(\n\u001b[0;32m    242\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    243\u001b[0m     ):\n\u001b[0;32m    244\u001b[0m         chunk\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mresponse_metadata \u001b[38;5;241m=\u001b[39m _gen_info_and_msg_metadata(chunk)\n\u001b[0;32m    245\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32mc:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\langchain_openai\\chat_models\\base.py:419\u001b[0m, in \u001b[0;36mChatOpenAI._stream\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    416\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m}\n\u001b[0;32m    418\u001b[0m default_chunk_class \u001b[38;5;241m=\u001b[39m AIMessageChunk\n\u001b[1;32m--> 419\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(messages\u001b[38;5;241m=\u001b[39mmessage_dicts, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[0;32m    420\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunk, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    421\u001b[0m         chunk \u001b[38;5;241m=\u001b[39m chunk\u001b[38;5;241m.\u001b[39mmodel_dump()\n",
      "File \u001b[1;32mc:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\openai\\_streaming.py:44\u001b[0m, in \u001b[0;36mStream.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[_T]:\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator:\n\u001b[0;32m     45\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m item\n",
      "File \u001b[1;32mc:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\openai\\_streaming.py:56\u001b[0m, in \u001b[0;36mStream.__stream__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     53\u001b[0m process_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39m_process_response_data\n\u001b[0;32m     54\u001b[0m iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_events()\n\u001b[1;32m---> 56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sse \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sse\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[DONE]\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     58\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\openai\\_streaming.py:48\u001b[0m, in \u001b[0;36mStream._iter_events\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_iter_events\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[ServerSentEvent]:\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoder\u001b[38;5;241m.\u001b[39miter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39miter_lines())\n",
      "File \u001b[1;32mc:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\openai\\_streaming.py:224\u001b[0m, in \u001b[0;36mSSEDecoder.iter\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21miter\u001b[39m(\u001b[38;5;28mself\u001b[39m, iterator: Iterator[\u001b[38;5;28mstr\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[ServerSentEvent]:\n\u001b[0;32m    223\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Given an iterator that yields lines, iterate over it & yield every event encountered\"\"\"\u001b[39;00m\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[0;32m    225\u001b[0m         line \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39mrstrip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    226\u001b[0m         sse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecode(line)\n",
      "File \u001b[1;32mc:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\httpx\\_models.py:861\u001b[0m, in \u001b[0;36mResponse.iter_lines\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    859\u001b[0m decoder \u001b[38;5;241m=\u001b[39m LineDecoder()\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request):\n\u001b[1;32m--> 861\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_text():\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m decoder\u001b[38;5;241m.\u001b[39mdecode(text):\n\u001b[0;32m    863\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m line\n",
      "File \u001b[1;32mc:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\httpx\\_models.py:848\u001b[0m, in \u001b[0;36mResponse.iter_text\u001b[1;34m(self, chunk_size)\u001b[0m\n\u001b[0;32m    846\u001b[0m chunker \u001b[38;5;241m=\u001b[39m TextChunker(chunk_size\u001b[38;5;241m=\u001b[39mchunk_size)\n\u001b[0;32m    847\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request):\n\u001b[1;32m--> 848\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m byte_content \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_bytes():\n\u001b[0;32m    849\u001b[0m         text_content \u001b[38;5;241m=\u001b[39m decoder\u001b[38;5;241m.\u001b[39mdecode(byte_content)\n\u001b[0;32m    850\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunker\u001b[38;5;241m.\u001b[39mdecode(text_content):\n",
      "File \u001b[1;32mc:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\httpx\\_models.py:829\u001b[0m, in \u001b[0;36mResponse.iter_bytes\u001b[1;34m(self, chunk_size)\u001b[0m\n\u001b[0;32m    827\u001b[0m chunker \u001b[38;5;241m=\u001b[39m ByteChunker(chunk_size\u001b[38;5;241m=\u001b[39mchunk_size)\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request):\n\u001b[1;32m--> 829\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m raw_bytes \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_raw():\n\u001b[0;32m    830\u001b[0m         decoded \u001b[38;5;241m=\u001b[39m decoder\u001b[38;5;241m.\u001b[39mdecode(raw_bytes)\n\u001b[0;32m    831\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunker\u001b[38;5;241m.\u001b[39mdecode(decoded):\n",
      "File \u001b[1;32mc:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\httpx\\_models.py:883\u001b[0m, in \u001b[0;36mResponse.iter_raw\u001b[1;34m(self, chunk_size)\u001b[0m\n\u001b[0;32m    880\u001b[0m chunker \u001b[38;5;241m=\u001b[39m ByteChunker(chunk_size\u001b[38;5;241m=\u001b[39mchunk_size)\n\u001b[0;32m    882\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request):\n\u001b[1;32m--> 883\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m raw_stream_bytes \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream:\n\u001b[0;32m    884\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_bytes_downloaded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(raw_stream_bytes)\n\u001b[0;32m    885\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunker\u001b[38;5;241m.\u001b[39mdecode(raw_stream_bytes):\n",
      "File \u001b[1;32mc:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\httpx\\_client.py:126\u001b[0m, in \u001b[0;36mBoundSyncStream.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mIterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[1;32m--> 126\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream:\n\u001b[0;32m    127\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n",
      "File \u001b[1;32mc:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\httpx\\_transports\\default.py:113\u001b[0m, in \u001b[0;36mResponseStream.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mIterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 113\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m part \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_httpcore_stream:\n\u001b[0;32m    114\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m part\n",
      "File \u001b[1;32mc:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\httpcore\\_sync\\connection_pool.py:367\u001b[0m, in \u001b[0;36mPoolByteStream.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\httpcore\\_sync\\connection_pool.py:363\u001b[0m, in \u001b[0;36mPoolByteStream.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 363\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m part \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream:\n\u001b[0;32m    364\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m part\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\httpcore\\_sync\\http11.py:349\u001b[0m, in \u001b[0;36mHTTP11ConnectionByteStream.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ShieldCancellation():\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m--> 349\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32mc:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\httpcore\\_sync\\http11.py:341\u001b[0m, in \u001b[0;36mHTTP11ConnectionByteStream.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_body\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request, kwargs):\n\u001b[1;32m--> 341\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39m_receive_response_body(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    342\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;66;03m# If we get an exception while streaming the response,\u001b[39;00m\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;66;03m# we want to close the response (and possibly the connection)\u001b[39;00m\n\u001b[0;32m    346\u001b[0m     \u001b[38;5;66;03m# before raising that exception.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\httpcore\\_sync\\http11.py:210\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_body\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    207\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 210\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mData):\n\u001b[0;32m    212\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mbytes\u001b[39m(event\u001b[38;5;241m.\u001b[39mdata)\n",
      "File \u001b[1;32mc:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\httpcore\\_sync\\http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[1;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[1;32mc:\\Users\\justa\\OneDrive\\Desktop\\Developer\\LLM-Enhanced-ATM\\venv_test\\lib\\site-packages\\httpcore\\_backends\\sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[1;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[1;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python39\\lib\\ssl.py:1226\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[1;34m(self, buflen, flags)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1223\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1224\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1225\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1226\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1228\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[1;32mC:\\Python39\\lib\\ssl.py:1101\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1099\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1101\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1102\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[0;32m   1103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "agent_executor.invoke(\n",
    "    {\"input\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OLLAMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The largest airport in the world is Hartsfield-Jackson Atlanta International Airport (ATL) in Atlanta, Georgia, USA.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "llm = Ollama(base_url=\"https://ollama.junzis.com\", model=\"gemma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on this information, the closest approach point between the two aircraft will be at the same position as their current position, which is:\\n\\n**N52\\'00\\'0.0\" E004\\'00\\'0.0\"**\\n\\nThis is because the two aircraft are directly opposite each other on the same latitude line, and their altitudes are the same.\\n\\nThe time at which this closest approach point will happen is not included in the text, therefore I cannot provide an answer for that question.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
<<<<<<< HEAD
   "name": "python",
=======
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
>>>>>>> dev
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
