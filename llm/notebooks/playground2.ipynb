{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.openai_assistant import OpenAIAssistantRunnable\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "from langchain.tools import E2BDataAnalysisTool\n",
    "import os\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.agents import tool, initialize_agent, AgentType, Tool\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents.format_scratchpad.openai_tools import (\n",
    "    format_to_openai_tool_messages,\n",
    ")\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser\n",
    "from langchain_anthropic.experimental import ChatAnthropicTools\n",
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e2b_data_analysis_tool = E2BDataAnalysisTool(api_key=os.getenv(\"E2B_API_KEY\"))\n",
    "\n",
    "\n",
    "@tool\n",
    "def install_python_package_to_e2b(package_name: str):\n",
    "    \"\"\"\n",
    "    Installs a python package to the E2B environment. This is useful for when you need to install a package that is not already installed in the E2B environment.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        e2b_data_analysis_tool.install_python_packages(package_name)\n",
    "        return f\"Successfully installed {package_name} to the E2B environment.\"\n",
    "    except Exception as e:\n",
    "        return f\"Failed to install {package_name} to the E2B environment. Error: {e}\"\n",
    "    \n",
    "\n",
    "tools = [e2b_data_analysis_tool, install_python_package_to_e2b]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPENAI Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# gpt-4-0125-preview\n",
    "# gpt-3.5-turbo-0125\n",
    "# gpt-3.5-turbo-instruct\n",
    "\n",
    "# Create a chat prompt template\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0,\n",
    "                 openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are very powerful air taffic control operator, that can also use tools to answer questions and perform tasks\",\n",
    "        ),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_tool_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | OpenAIToolsAgentOutputParser()\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent, tools=tools, verbose=True, return_intermediate_steps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.invoke(\n",
    "    {\"input\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReACT Anthropic Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Artifacts are charts created by matplotlib when `plt.show()` is called\n",
    "def save_artifact(artifact):\n",
    "    print(\"New matplotlib chart generated:\", artifact.name)\n",
    "    # Download the artifact as `bytes` and leave it up to the user to display them (on frontend, for example)\n",
    "    file = artifact.download()\n",
    "    basename = os.path.basename(artifact.name)\n",
    "\n",
    "    # Save the chart to the `charts` directory\n",
    "    with open(f\"./charts/{basename}\", \"wb\") as f:\n",
    "        f.write(file)\n",
    "\n",
    "\n",
    "e2b_data_analysis_tool = E2BDataAnalysisTool(\n",
    "    api_key=os.getenv(\"E2B_API_KEY\"),\n",
    "    on_stdout=lambda stdout: print(\"stdout:\", stdout),\n",
    "    on_stderr=lambda stderr: print(\"stderr:\", stderr),\n",
    "    on_artifact=save_artifact,\n",
    ")\n",
    "\n",
    "tools = [e2b_data_analysis_tool.as_tool(), install_python_package_to_e2b]\n",
    "\n",
    "\n",
    "\n",
    "# Choose the LLM to use\n",
    "#llm = ChatOpenAI(model='gpt-4-0125-preview')\n",
    "llm = ChatAnthropicTools(model='claude-3-sonnet-20240229',anthropic_api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n",
    "\n",
    "#llm = ChatOpenAI()\n",
    "# Get the prompt to use - you can modify this!\n",
    "#prompt = hub.pull(\"hwchase17/react\")\n",
    "# Construct the ReAct agent\n",
    "agent = initialize_agent(tools=tools, llm=llm, verbose=True,\n",
    "                         agent=AgentType.OPENAI_FUNCTIONS)\n",
    "# Create an agent executor by passing in the agent and tools\n",
    "#agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "agent.run(question)\n",
    "#agent_executor.invoke({\"input\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_react_agent\n",
    "from langchain_community.chat_models import ChatAnthropic\n",
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "\n",
    "tools = [PythonREPLTool()]\n",
    "\n",
    "instructions = \"\"\"You are an agent designed to write and execute python code to answer questions.\n",
    "You have access to a python REPL, which you can use to execute python code.\n",
    "If you get an error, debug your code and try again.\n",
    "Only use the output of your code to answer the question. \n",
    "You might know the answer without running any code, but you should still run the code to get the answer.\n",
    "If it does not seem like you can write code to answer the question, just return \"I don't know\" as the answer.\n",
    "\"\"\"\n",
    "llm = ChatAnthropic(anthropic_api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n",
    "llm = ChatOpenAI(model=\"gpt-4-0125-preview\")\n",
    "base_prompt = hub.pull(\"langchain-ai/react-agent-template\")\n",
    "prompt = base_prompt.partial(instructions=instructions)\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "agent_executor.invoke({\"input\": question})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
