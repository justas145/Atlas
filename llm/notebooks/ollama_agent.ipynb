{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "from operator import itemgetter\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OllamaFunctions(model=\"phi3:latest\", format=\"json\", keep_alive=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.invoke('hi there!, tell why 2+2 is 5?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import random\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.tools import tool\n",
    "import random\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "\n",
    "\n",
    "@tool\n",
    "def fake_weather_api(city: str) -> str:\n",
    "    \"\"\"Check the weather in a specified city. The API is available randomly, approximately every third call.\"\"\"\n",
    "\n",
    "    if random.randint(1, 3) == 1:  # Approximately one-third chance\n",
    "        return \"Sunny, 22Â°C\"\n",
    "    else:\n",
    "        return \"Service temporarily unavailable\"\n",
    "\n",
    "\n",
    "tools = [fake_weather_api]\n",
    "functions = [convert_to_openai_function(tool) for tool in tools]\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Make sure to use the tavily_search_results_json tool for information.\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Construct the Tools agent\n",
    "agent = create_tool_calling_agent(model, functions, prompt)\n",
    "# Create an agent executor by passing in the agent and tools\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "agent_executor.invoke({\"input\": \"what is LangChain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"\n",
    "    Get the weather for a location\n",
    "\n",
    "    \"\"\"\n",
    "    return \"weather in \" + location + \" is sunny with a high of 75 degrees\"\n",
    "\n",
    "@tool\n",
    "def get_population(location: str) -> str:\n",
    "    \"\"\"\n",
    "    Get the population of a location\n",
    "\n",
    "    \"\"\"\n",
    "    return \"the population of \" + location + \" is 100,000\"\n",
    "\n",
    "\n",
    "tools = [get_weather, get_population]\n",
    "functions = [convert_to_openai_function(t) for t in tools]\n",
    "tool_mapping = {\"get_weather\": get_weather, \"get_population\": get_population}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.bind_tools(functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.invoke(\"what is the weather in Boston and its population?\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.additional_kwargs[\"function_call\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.additional_kwargs | itemgetter(\"arguments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_openai_tools_agent"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
